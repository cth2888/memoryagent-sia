<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8" />
    <meta name="description"
        content="MemAgent: Reshaping Long-Context LLM with Mult-Conv RL based Memory Agent" />
    <meta name="Long context, reasoning, large lanuge model, LLM"
        content="MemAgent" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>MemAgent: Reshaping Long-Context LLM with Mult-Conv RL based Memory Agent</title>

    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet" />
    <link rel="stylesheet" href="./css/bulma.min.css" />
    <link rel="stylesheet" href="./css/bulma-carousel.min.css" />
    <link rel="stylesheet" href="./css/bulma-slider.min.css" />
    <link rel="stylesheet" href="./css/fontawesome.all.min.css" />
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css" />
    <link rel="stylesheet" href="./css/index.css" />
    <link rel="stylesheet" href="./css/enhanced-styles.css" />
    <link rel="stylesheet" href="./css/final-enhancements.css" />
    <link rel="stylesheet" href="./css/navbar-fix.css" />
    <link rel="stylesheet" href="./css/navbar-alignment-fix.css" />
    <link rel="stylesheet" href="./css/overlap-fix.css" />
    <link rel="stylesheet" href="./css/spacing-fix.css" />
    <link rel="stylesheet" href="./css/author-affiliation-styles.css" />
    <link rel="icon" href="./assets/doubao.png" type="image/png" />

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script defer src="./js/fontawesome.all.min.js"></script>
    <script src="./js/bulma-carousel.min.js"></script>
    <script src="./js/bulma-slider.min.js"></script>
    <script src="./js/index.js"></script>
    <script src="./js/enhanced-animations.js"></script>
    <script src="./js/language-switcher.js"></script>
    <script src="https://cdn.tailwindcss.com"></script>
    <script>
        MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\\(', '\\)']],
                displayMath: [['$$', '$$'], ['\\[', '\\]']]
            },
            svg: {
                fontCache: 'global'
            }
        };
    </script>
    <script type="text/javascript" id="MathJax-script" async
        src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js">
    </script>
</head>

<body>
    <nav class="navbar is-fixed-top" role="navigation" aria-label="main navigation">
        <div class="container">
            <div class="navbar-brand">
                <a class="navbar-item" href="#">
                    🧩 MemAgent
                </a>
                <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
                    <span aria-hidden="true"></span>
                    <span aria-hidden="true"></span>
                    <span aria-hidden="true"></span>
                </a>
            </div>
            <div class="navbar-menu">
                <div class="navbar-end">
                    <a class="navbar-item" href="#introduction">
                        <span lang="en">Introduction</span>
                        <span lang="zh">引言</span>
                    </a>
                    <a class="navbar-item" href="#method">
                        <span lang="en">Method</span>
                        <span lang="zh">方法介绍</span>
                    </a>
                    <a class="navbar-item" href="#experiments">
                        <span lang="en">Experimental analysis</span>
                        <span lang="zh">实验分析</span>
                    </a>
                    <a class="navbar-item" href="#engineering">
                        <span lang="en">Engineering</span>
                        <span lang="zh">工程</span>
                    </a>
                    <a class="navbar-item" href="#citation">
                        <span lang="en">Citation</span>
                        <span lang="zh">引用</span>
                    </a>

                    <button id="language-toggle" class="navbar-item language-toggle">中文</button>
                </div>
            </div>
        </div>
    </nav>
    
    <section class="hero">
        <div class="hero-body">
            <div class="container">
                <div class="has-text-centered">
                    <h1 class="publication-title">
                        <span lang="en"><em class="dnerf">MemAgent</em>: Reshaping Long-Context LLM with Mult-Conv RL based Memory Agent</span>
                        <span lang="zh"><em class="dnerf">MemAgent</em>: Reshaping Long-Context LLM with Mult-Conv RL based Memory Agent</span>
                    </h1>
                    <div class="publication-authors">
                        <span class="author-block">
                            <span lang="en"><a href="https://seed-enigmata.github.io/">Hongli Yu</a><sup>1,3,6</sup></span>
                            <span lang="zh"><a href="https://seed-enigmata.github.io/">于鸿利</a><sup>1,3,6</sup></span>
                        </span>
                        <span class="author-block">
                            <span lang="en"><a href="https://zhouh.github.io/">Hao Zhou</a><sup>3,6</sup></span>
                            <span lang="zh"><a href="https://zhouh.github.io/">周浩</a><sup>3,6</sup></span>
                        </span>
                    </div>
                    <div class="publication-affiliations">
                        <span class="affiliation-block">
                            <span lang="en"><sup>1</sup>ByteDance Seed</span>
                            <span lang="zh"><sup>1</sup>字节跳动 Seed</span>
                        </span><br>
                        <span class="affiliation-block">
                            <span lang="en"><sup>3</sup>Institute for AI Industry Research (AIR), Tsinghua University</span>
                            <span lang="zh"><sup>3</sup>清华大学 智能产业研究院（AIR）</span>
                        </span><br>
                        <span class="affiliation-block">
                            <span lang="en"><sup>6</sup>SIA-Lab of Tsinghua AIR and ByteDance Seed</span>
                            <span lang="zh"><sup>6</sup>清华-字节联合实验室SIA-Lab</span>
                        </span>
                        <div class="affiliation-note">
                            <span lang="en">*Project Lead; †Equal Contribution</span>
                            <span lang="zh">*项目负责人; †同等贡献</span>
                        </div>
                        <div class="affiliation-note">
                            <span lang="en">Contact: <a href="mailto:jiangjiec@bytedance.com">jiangjiec@bytedance.com</a></span>
                            <span lang="zh">联系方式: <a href="mailto:jiangjiec@bytedance.com">jiangjiec@bytedance.com</a></span>
                        </div>
                    </div>
                    <div class="publication-links">
                        <span class="link-block">
                            <a href="http://arxiv.org/abs/2505.19914" class="external-link button is-dark">
                                <span class="icon">
                                    <i class="fas fa-file-pdf"></i>
                                </span>
                                <span lang="en">Paper</span>
                                <span lang="zh">论文</span>
                            </a>
                        </span>
                        <span class="link-block">
                            <a href="https://github.com/BytedTsinghua-SIA/Enigmata" class="external-link button is-dark">
                                <span class="icon">
                                    <i class="fas fa-database"></i>
                                </span>
                                <span lang="en">Code</span>
                                <span lang="zh">代码</span>
                            </a>
                        </span>
                        <span class="link-block">
                            <a href="https://huggingface.co/datasets/BytedTsinghua-SIA/Enigmata-Eval" class="external-link button is-dark">
                                <span class="icon">
                                    <i class="fas fa-database"></i>
                                </span>
                                <span lang="en">Evaluation</span>
                                <span lang="zh">评估</span>
                            </a>
                        </span>
                        <span class="link-block">
                            <a href="https://huggingface.co/BytedTsinghua-SIA/Enigmata-Qwen2.5-32B" class="external-link button is-dark">
                                <span class="icon">
                                    🤗
                                </span>
                                <span lang="en">Model</span>
                                <span lang="zh">模型</span>
                            </a>
                        </span>
                    </div>
                </div>
            </div>
        </div>
    </section>

<section class="section" id="introduction">
    <div class="container">
        <div class="columns is-centered">
            <div class="column is-10">
                <h2 class="title is-3">
                    <span lang="en">Introduction</span>
                    <span lang="zh">引言</span>
                </h2>
                <div class="content">

                    <p lang="en">
                        We present <strong>RL-Memory Agent</strong>, a novel framework for long-text processing that directly optimizes task performance through end-to-end reinforcement learning, without any architectural modifications to the base model.
                    </p>
                    <p lang="zh">
                        我们推出了<strong>RL-Memory Agent</strong>，这是一个全新的长文本处理框架，能够通过端到端的强化学习直接优化长文本任务性能，而无需更改底层模型架构。
                    </p>
                    <p lang="en">
                        <strong>RL-Memory Agent</strong> achieves three major breakthroughs:
                    </p>

                    <p lang="zh">
                        <strong>RL-Memory Agent</strong> 实现了三大核心突破：
                    </p>
                    <div
                        style="background-color: #f8fafc; border-radius: 12px; border-left: 6px solid #3a76ed; padding: 1.2rem; margin-bottom: 1.5rem;">
                            <div style="display: flex; flex-direction: column; gap: 0.8rem;">
                                <div style="display: flex; align-items: flex-start; gap: 0.8rem;"> 
                                    <div
                                        style="background-color: #3a76ed; color: white; padding: 0.4rem; border-radius: 50%; font-size: 0.9rem; display: flex; align-items: center; justify-content: center; min-width: 2rem; height: 2rem;">
                                        1
                                    </div>
                                    <div>
                                        <p style="margin: 0; line-height: 1.4;" lang="en"><strong>Novel memory mechanism: </strong>
                                            It introduces a notebook-style workflow where the agent reads input in segments and efficiently updates memory using an overwrite strategy. This enables handling virtually unlimited-length inputs within a fixed context window, fundamentally breaking the hard length limits of Transformer models.</p>
                                        <p style="margin: 0; line-height: 1.4;" lang="zh"><strong>新型记忆机制：</strong>
                                            我们引入了一种记事本式的工作流，Agent 以分段方式读取文本，并借助覆写策略高效更新记忆。该设计使得模型能够在固定上下文窗口内处理几乎任意长度的输入，从根本上突破了传统 Transformer 架构的窗口长度限制。</p>
                                    </div>
                                </div>
                                
                                <div style="display: flex; align-items: flex-start; gap: 0.8rem;">
                                    <div
                                        style="background-color: #3a76ed; color: white; padding: 0.4rem; border-radius: 50%; font-size: 0.9rem; display: flex; align-items: center; justify-content: center; min-width: 2rem; height: 2rem;">
                                        2
                                    </div>
                                    <div>
                                    <p style="margin: 0; line-height: 1.4;" lang="en"><strong>O(n) linear complexity:</strong> 
                                        The agent design decouples compute and memory cost from input length, reducing the processing burden from quadratic to linear with respect to input size.</p>
                                    <p style="margin: 0; line-height: 1.4;" lang="zh"><strong>O(n) 线性复杂度：</strong>
                                        这一创新性的 Agent 设计将计算与显存开销与文本长度解耦，使得处理长文本的复杂度由原本的二次方增长转变为线性增长。</p>
                                    </div>
                                </div>

                                <div style="display: flex; align-items: flex-start; gap: 0.8rem;">
                                    <div
                                        style="background-color: #3a76ed; color: white; padding: 0.4rem; border-radius: 50%; font-size: 0.9rem; display: flex; align-items: center; justify-content: center; min-width: 2rem; height: 2rem;">
                                        3
                                    </div>
                                    <div>
                                        <p style="margin: 0; line-height: 1.4;" lang="en"><strong>RL-driven extrapolation:</strong>
                                            A modified GRPO algorithm supports training on multi-turn generation tasks with independent contexts. As a result, models trained with 32K contexts can extrapolate to 3.5M-token sequences with <5% performance drop.</p>
                                        <p style="margin: 0; line-height: 1.4;" lang="zh"><strong>强化学习驱动的外推能力:</strong>
                                            我们改进了 GRPO 算法，使其支持独立上下文的多轮生成训练。基于此，训练出的 Memory Agent 在32K上下文长度的数据上训练后，能够无损外推至3.5M token的问答任务中，性能下降低于5%。</p>
                                    </div>
                                </div>                                
                            </div>
                    </div>

                    <p lang="en">
                        In a simple yet effective way, we demonstrate—for the first time—a trainable memory ability empowered by reinforcement learning. RL-Memory Agent showcases the untapped potential of optimizing specialized workflows via policy learning rather than architectural changes.
                    </p>
                    <p lang="zh">
                        我们以一种简洁而高效的方式，首次实现了真正意义上的、由强化学习赋予的可训练记忆能力，充分展现了强化学习在优化特定工作流方面的巨大潜力。
                    </p>

                    <strong><em style="color: #3a76ed"><center lang="en">We believe RL-Memory Agent paves the way for the next generation of scalable long-context LLMs.</center></em></strong>
                    <strong><em style="color: #3a76ed"><center lang="zh">我们相信，RL-Memory Agent 为下一代可扩展的长上下文大语言模型开辟了新路径。</center></em></strong>

                </div>
            </div>
        </div>
    </div>
</section>

<section class="section" id="method">
    <div class="container">
        <div class="columns is-centered">
            <div class="column is-10">
                <h2 class="title is-3">
                    <span lang="en">Method</span>
                    <span lang="zh">方法介绍</span>
                </h2>
                <div class="content">

                    <h3 class="title is-4" lang="zh">Memory Agent 框架</h3>
                    <p lang="zh">
                        受人类处理长文本时的行为模式启发，并借鉴了Nerual Truing machine和Memory Network等神经网络与记忆机制结合的工作，我们提出了一种无需修改模型架构的长文处理新方案：
                    </p>
                    <p lang="zh" style="color:#3273dc;">
                        <strong>| 给LLM装上动态更新的“记忆模块”</strong>
                    </p>
                    <p lang="zh">
                        Memory Agent 引入了一个固定长度的辅助记忆面板，允许模型在处理长文本时以分段的方式读取输入，并在每一段之后主动更新记忆状态，从而实现“局部处理 + 全局融合”的新型工作流。该记忆模块在推理过程中不断动态更新，并在所有段落处理完毕后，通过聚合记忆中的关键信息协助生成最终输出。
                    </p>

                    <hr>

                    <h3 class="title is-4" lang="zh">传统文本建模</h3>
                    <p lang="zh">
                        传统的自回归语言模型通过以下方式建模长度为N的token序列：
                    </p>
                    <div class="content has-text-centered">
                        $$p(\mathbf{x}_{1:N})=p(x_1)\prod_{n=2}^{N}p(x_n \mid \mathbf{x}_{1:n-1})$$
                    </div>
                    <p lang="zh">
                        这种方法需要缓存所有先前生成的token，导致计算成本随序列长度呈二次方增长。
                    </p>

                    <hr>

                    <h3 class="title is-4" lang="zh">Memory Agent核心架构</h3>
                    <ul lang="zh">
                        <li><strong>分块处理：</strong> 将输入序列分割为K个连续块 <span class="nowrap-math">\((c^1, c^2, \ldots, c^K)\)</span>，每块最多包含 <span class="nowrap-math">\(C\)</span> 个token。</li>
                        <li><strong>循环处理：</strong> 按块顺序处理，每块的计算成本保持恒定。</li>
                        <li><strong>重新建模语言模型的生成过程</strong></li>
                    </ul>
                    <p lang="zh">
                        引入潜在记忆变量 <span class="nowrap-math">\(m^{1:K-1}\)</span> 和初始状态 <span class="nowrap-math">\(m^0 = \varnothing\)</span> 后，自回归分解被重新表述为：
                    </p>
                    <div class="content has-text-centered">
                        $$p(\mathbf{x}_{1:N}) = \sum_{\mathbf{m}^{1:K-1}} \prod_{k=1}^{K}
                        \underbrace{p(\mathbf{c}^k \mid \mathbf{m}^{k-1})}_{\text{read}} \cdot
                        \underbrace{p(\mathbf{m}^k \mid \mathbf{c}^k, \mathbf{m}^{k-1})}_{\text{write}}$$
                    </div>
                     <figure class="image" style="max-width: 800px; margin: 2rem auto;">
                        <img src="figs/method_00.png" alt="Memory Agent Architecture Overview">
                    </figure>

                    <hr>

                    <h3 class="title is-4" lang="zh">Memory agent 强化学习训练流程：</h3>
                    <p lang="zh">
                        我们使用目前在推理领域表现出卓越性能的基于可验证结果的强化学习（RLVR)来训练Memory agent，而非简单的进行微调或指令工程。为此，我们扩展了现有的DAPO算法，使其进一步支持了具有多轮独立对话的AgentWorkflow的端到端优化。
                    </p>
                    <div class="columns is-vcentered">
                        <div class="column">
                            <figure class="image">
                                <img src="figs/algo_00.png" alt="RL Flow">
                            </figure>
                        </div>
                        <div class="column">
                            <figure class="image">
                                <img src="figs/template.png" alt="RL Template">
                            </figure>
                        </div>
                    </div>

                    <h4 class="title is-5" lang="zh">多轮对话训练机制：</h4>
                    <p lang="zh">对于每个输入样本，会通过模型并行生成多组独立对话序列。</p>
                    <h4 class="title is-5" lang="zh">奖励计算与分配：</h4>
                    <p lang="zh">系统根据最后一组回答，识别最终答案，计算其奖励值，然后将该奖励通过组归一化方式智能分配到所有关联对话序列。</p>
                    <h4 class="title is-5" lang="zh">策略优化目标：</h4>
                    <p lang="zh">以每个chunk为单位计算损失（如下图所示），采用（组别、对话轮次、token）三维优化结构，整个过程保持各对话的独立性：</p>
                    <div class="column">
                        <figure class="image">
                            <img src="figs/train_loss.png" alt="Train loss">
                        </figure>
                    </div>

                </div>
            </div>
        </div>
    </div>
</section>



<section class="section" id="experiments">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-10">
        <h2 class="title is-3">
          <span lang="en">Experiments</span>
          <span lang="zh">实验分析</span>
        </h2>
        <div class="content">

          <h4 lang="en"><strong>Main Results</strong></h4>
          <h4 lang="zh"><strong>主实验结果</strong></h4>

          <p lang="zh">
            <strong>基线模型：</strong> 实验显示，现有长文本模型在超长序列上普遍存在严重的性能退化：
            <ul>
              <li>QwenLong-L1系列：在文本长度超过56K后准确率急剧下降，降幅超过40个百分点。</li>
              <li>Qwen2.5-Instruct-1M系列：标称支持1M，但在896K时性能降为0。</li>
              <li>DS-distill系列：性能随长度呈指数级衰减，在224K时几乎完全失效。</li>
            </ul>
          </p>

          <p lang="zh">
            <strong>RL-Memory Agent：</strong> 在超长文本处理任务中表现出极高稳定性：
            <ul>
              <li>RL-Memory Agent-14B：在3.5M超长文本测试中仅出现边际性能下降（<5%），实现了无损外推。</li>
              <li>RL-Memory Agent-7B：在最长文本上虽略有性能下降，但总体表现远超其他模型。</li>
            </ul>
          </p>

          <figure class="image" style="max-width: 800px; margin: 2rem auto;">
            <img src="figs/main_result_00.png" alt="Main Results">
          </figure>

          <h4 lang="zh"><strong>消融实验</strong></h4>
          <p lang="zh">
            为验证Memory Agent各组件的贡献，我们开展了系统的消融实验：
            <ol>
              <li><strong>基础模型：</strong> 在超出训练窗口后，信息缺失导致性能急剧下降，无法实现外推。</li>
              <li><strong>Memory Agent（未RL训练）：</strong> 具备一定处理能力，但在长文本任务下仍出现明显性能损失。</li>
              <li><strong>RL-Memory Agent：</strong> 强化学习训练显著提升外推能力，达到近乎无损性能。</li>
            </ol>
          </p>

          <figure class="image" style="max-width: 800px; margin: 2rem auto;">
            <img src="figs/ablation_00.png" alt="Ablation Study">
          </figure>

          <h4 lang="zh"><strong>RULER基准测试与OOD能力分析</strong></h4>
          <p lang="zh">
            <strong>RULER基准测试：</strong> 这是当前长文本外推能力研究的标准测试集，其核心优势是可控长度生成任务。
          </p>

          <div class="box" style="background: #f8f9fa; border: 1px solid #ddd; border-radius: 10px; padding: 1.5rem;">
            <div class="columns is-multiline is-variable is-4">
              <div class="column is-6">
                <div class="box has-background-white-ter">
                  <strong>大海捞针（Needle-in-a-Haystack）</strong>
                  <p>在超长文本中定位关键needle，包含8类干扰变体。</p>
                </div>
              </div>
              <div class="column is-6">
                <div class="box has-background-white-ter">
                  <strong>变量追踪（Variable Tracking）</strong>
                  <p>模拟程序分析场景，追踪变量引用和赋值关系。</p>
                </div>
              </div>
              <div class="column is-6">
                <div class="box has-background-white-ter">
                  <strong>聚合任务（Aggregation）</strong>
                  <p>汇总分散信息，评估模型对全局特征的掌握能力。</p>
                </div>
              </div>
              <div class="column is-6">
                <div class="box has-background-white-ter">
                  <strong>问答任务（QA）</strong>
                  <p>进行多跳复杂推理，测试模型上下文理解与问答能力。</p>
                </div>
              </div>
            </div>
          </div>

          <p lang="zh">
            <strong>实验结果分析：</strong> 我们使用热力图可视化不同模型在不同长度区间和任务类型下的性能：
            <ul>
              <li><strong>RL-Memory Agent：</strong> 所有任务类型上均优于现有模型，展现显著性能优势。</li>
              <li><strong>Memory Agent（未训练）：</strong> 在大多数情况下优于基础模型，但外推长度上仍出现性能下降。</li>
              <li><strong>基础模型：</strong> Distill/Instruct系列在超长文本任务中普遍失败。</li>
              <li><strong>QwenLong系列：</strong> 在超长文本下性能剧降，甚至不如基础模型。</li>
              <li><strong>Qwen-1M系列：</strong> 在简单任务上表现尚可，但在复杂推理任务中急剧下降。</li>
            </ul>
          </p>

          <div class="columns is-multiline">
            <div class="column is-4">
              <figure class="image"><img src="figs/niah_single_1_00.png" alt="NIAH Single 1"></figure>
            </div>
            <div class="column is-4">
              <figure class="image"><img src="figs/niah_single_2_00.png" alt="NIAH Single 2"></figure>
            </div>
            <div class="column is-4">
              <figure class="image"><img src="figs/niah_single_3_00.png" alt="NIAH Single 3"></figure>
            </div>

            <div class="column is-4">
              <figure class="image"><img src="figs/niah_multikey_1_00.png" alt="NIAH Multi 1"></figure>
            </div>
            <div class="column is-4">
              <figure class="image"><img src="figs/niah_multikey_2_00.png" alt="NIAH Multi 2"></figure>
            </div>
            <div class="column is-4">
              <figure class="image"><img src="figs/niah_multikey_3_00.png" alt="NIAH Multi 3"></figure>
            </div>

            <div class="column is-6">
              <figure class="image"><img src="figs/niah_multiquery_00.png" alt="Multi-query"></figure>
            </div>
            <div class="column is-6">
              <figure class="image"><img src="figs/niah_multivalue_00.png" alt="Multi-value"></figure>
            </div>

            <div class="column is-6">
              <figure class="image"><img src="figs/fwe_00.png" alt="FWE"></figure>
            </div>
            <div class="column is-6">
              <figure class="image"><img src="figs/vt_00.png" alt="VT"></figure>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="section" id="conclusion">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-10">
        <h2 class="title is-3">
          <span lang="en">Conclusion</span>
          <span lang="zh">总结</span>
        </h2>
        <div class="content">
          <p lang="zh">
            本研究提出了一种全新的长文本处理框架 <strong>RL-Memory Agent</strong>，在以下三个关键维度实现了重要突破：
          </p>
          <ul>
            <li><strong>技术架构突破：</strong> 提出一种创新机制，使大语言模型在固定窗口限制下仍能以 <strong>线性复杂度</strong>处理任意长度文本，从根本上突破传统Transformer的计算瓶颈。</li>
            <li><strong>智能体训练方法：</strong> 构建了一整套强化学习驱动的智能体工作流，基于 <strong>多对话GRPO</strong> 实现端到端训练机制。</li>
            <li><strong>性能外推验证：</strong> 大量实验表明，RL训练能够帮助模型外推至远超训练窗口的任务中，<strong>性能下降<5%</strong>，显著扩展LLM能力边界。</li>
          </ul>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section" id="engineering">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-10">
        <h2 class="title is-3">
          <span lang="en">Engineering Bonus</span>
          <span lang="zh">工程彩蛋</span>
        </h2>
        <div class="content">
          <p lang="zh">
            <strong>RL-Memory Agent</strong> 的成功不仅依赖于理论方法，还得益于工程系统的创新性支持。我们提出了一种适配大模型训练的新型异步架构，并实现了接口统一，显著提升了训练效率与易用性。
          </p>
          <ul>
            <li><strong>纯异步流水线：</strong> GPU/CPU资源解耦，<code>AsyncLLMEngine</code> 负责多节点推理，<code>Ray Worker</code>管理常驻CPU任务池，通过协程完成资源调度。</li>
            <li><strong>统一API接口：</strong> 兼容 OpenAI API 与 vLLM 推理，支持 <strong>多轮工具调用、多Agent并行、多任务训练</strong>，真正消除传统状态机地狱。</li>
            <li><strong>易用性显著提升：</strong> 训练流程只需编写一个标准 OpenAI 接口函数，即可完成复杂上下文拼接、token处理与状态管理。</li>
          </ul>

          <figure class="image" style="max-width: 800px; margin: 2rem auto;">
            <img src="figs/workflow1.png" alt="Async Engine Workflow 1">
          </figure>
          <figure class="image" style="max-width: 800px; margin: 2rem auto;">
            <img src="figs/workflow2.png" alt="Async Engine Workflow 2">
          </figure>
        </div>
      </div>
    </div>
  </div>
</section>


    <section class="section" id="citation">
        <div class="container">
            <div class="columns is-centered">
                <div class="column is-10">
                    <h2 class="title is-3">
                        <span lang="en">📝 Citation</span>
                        <span lang="zh">📝 引用</span>
                    </h2>
                    <div class="content">
                        <p lang="en">If you find this work useful, please cite our paper:</p>
                        <p lang="zh">如果您发现这项工作有用，请引用我们的论文：</p>
                        <pre><code class="latex">
@article{chen2025enigmata,
    title={Enigmata: Scaling Logical Reasoning in Large Language Models with Synthetic Verifiable Puzzles},
    author={Chen, Jiangjie and He, Qianyu and Yuan, Siyu and Chen, Aili and Cai, Zhicheng and Dai, Weinan and Yu, Hongli and Yu, Qiying and Li, Xuefeng and Chen, Jiaze and others},
    journal={arXiv preprint arXiv:2505.19914},
    year={2025}
}
                        </code></pre>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <footer class="footer">
        <div class="container">
            <div class="has-text-centered">
                <p>
                    <span lang="en">© 2025 <a href="https://seed.bytedance.com">ByteDance Seed</a>. Modified from <a href="https://github.com/seed-enigmata/seed-enigmata.github.io">R2E-Gym</a>.</span>
                    <span lang="zh">© 2025 <a href="https://seed.bytedance.com">字节跳动Seed</a>. 修改自 <a href="https://github.com/seed-enigmata/seed-enigmata.github.io">R2E-Gym</a>.</span>
                </p>
            </div>
        </div>
    </footer>


</body>


</html>
