<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8" />
    <meta name="description"
        content="MemAgent: Reshaping Long-Context LLM with Mult-Conv RL based Memory Agent" />
    <meta name="Long context, reasoning, large lanuge model, LLM"
        content="MemAgent" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>MemAgent: Reshaping Long-Context LLM with Mult-Conv RL based Memory Agent</title>

    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet" />
    <link rel="stylesheet" href="./css/bulma.min.css" />
    <link rel="stylesheet" href="./css/bulma-carousel.min.css" />
    <link rel="stylesheet" href="./css/bulma-slider.min.css" />
    <link rel="stylesheet" href="./css/fontawesome.all.min.css" />
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css" />
    <link rel="stylesheet" href="./css/index.css" />
    <link rel="stylesheet" href="./css/enhanced-styles.css" />
    <link rel="stylesheet" href="./css/final-enhancements.css" />
    <link rel="stylesheet" href="./css/navbar-fix.css" />
    <link rel="stylesheet" href="./css/navbar-alignment-fix.css" />
    <link rel="stylesheet" href="./css/overlap-fix.css" />
    <link rel="stylesheet" href="./css/spacing-fix.css" />
    <link rel="stylesheet" href="./css/author-affiliation-styles.css" />
    <link rel="icon" href="./assets/doubao.png" type="image/png" />

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script defer src="./js/fontawesome.all.min.js"></script>
    <script src="./js/bulma-carousel.min.js"></script>
    <script src="./js/bulma-slider.min.js"></script>
    <script src="./js/index.js"></script>
    <script src="./js/enhanced-animations.js"></script>
    <script src="./js/language-switcher.js"></script>
    <script src="https://cdn.tailwindcss.com"></script>
    <script>
        MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\\(', '\\)']],
                displayMath: [['$$', '$$'], ['\\[', '\\]']]
            },
            svg: {
                fontCache: 'global'
            }
        };
        
    </script>
    <script type="text/javascript" id="MathJax-script" async
        src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js">
    </script>
    <style>
        .nowrap-math {
            white-space: nowrap;
            display: inline-block;
        }
        .has-text-centered {
            text-align: center !important;
        }
        .content .has-text-centered {
            margin: 1.5rem 0;
        }
        /* é˜²æ­¢æ•°å­¦å…¬å¼æ¢è¡Œ */
        .MathJax {
            white-space: nowrap !important;
        }
        /* ç¡®ä¿å±…ä¸­çš„æ•°å­¦å…¬å¼å— */
        .math-center {
            display: block;
            text-align: center;
            margin: 1.5rem 0;
            overflow-x: auto;
        }
    </style>

</head>

<body>
    <nav class="navbar is-fixed-top" role="navigation" aria-label="main navigation">
        <div class="container">
            <div class="navbar-brand">
                <a class="navbar-item" href="#">
                    ğŸ§© MemAgent
                </a>
                <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
                    <span aria-hidden="true"></span>
                    <span aria-hidden="true"></span>
                    <span aria-hidden="true"></span>
                </a>
            </div>
            <div class="navbar-menu">
                <div class="navbar-end">
                    <a class="navbar-item" href="#introduction">
                        <span lang="en">Introduction</span>
                        <span lang="zh">å¼•è¨€</span>
                    </a>
                    <a class="navbar-item" href="#method">
                        <span lang="en">Method</span>
                        <span lang="zh">æ–¹æ³•ä»‹ç»</span>
                    </a>
                    <a class="navbar-item" href="#experiments">
                        <span lang="en">Experimental analysis</span>
                        <span lang="zh">å®éªŒåˆ†æ</span>
                    </a>
                    <a class="navbar-item" href="#engineering">
                        <span lang="en">Engineering</span>
                        <span lang="zh">å·¥ç¨‹</span>
                    </a>
                    <a class="navbar-item" href="#citation">
                        <span lang="en">Citation</span>
                        <span lang="zh">å¼•ç”¨</span>
                    </a>

                    <button id="language-toggle" class="navbar-item language-toggle">ä¸­æ–‡</button>
                </div>
            </div>
        </div>
    </nav>
    
    <section class="hero">
        <div class="hero-body">
            <div class="container">
                <div class="has-text-centered">
                    <h1 class="publication-title">
                        <span lang="en"><em class="dnerf">MemAgent</em>: Reshaping Long-Context LLM with Mult-Conv RL based Memory Agent</span>
                        <span lang="zh"><em class="dnerf">MemAgent</em>: Reshaping Long-Context LLM with Mult-Conv RL based Memory Agent</span>
                    </h1>
                    <div class="publication-authors">
                        <span class="author-block">
                            <span lang="en"><a href="https://seed-enigmata.github.io/">Hongli Yu</a><sup>1,3,6</sup></span>
                            <span lang="zh"><a href="https://seed-enigmata.github.io/">äºé¸¿åˆ©</a><sup>1,3,6</sup></span>
                        </span>
                        <span class="author-block">
                            <span lang="en"><a href="https://zhouh.github.io/">Hao Zhou</a><sup>3,6</sup></span>
                            <span lang="zh"><a href="https://zhouh.github.io/">å‘¨æµ©</a><sup>3,6</sup></span>
                        </span>
                    </div>
                    <div class="publication-affiliations">
                        <span class="affiliation-block">
                            <span lang="en"><sup>1</sup>ByteDance Seed</span>
                            <span lang="zh"><sup>1</sup>å­—èŠ‚è·³åŠ¨ Seed</span>
                        </span><br>
                        <span class="affiliation-block">
                            <span lang="en"><sup>3</sup>Institute for AI Industry Research (AIR), Tsinghua University</span>
                            <span lang="zh"><sup>3</sup>æ¸…åå¤§å­¦ æ™ºèƒ½äº§ä¸šç ”ç©¶é™¢ï¼ˆAIRï¼‰</span>
                        </span><br>
                        <span class="affiliation-block">
                            <span lang="en"><sup>6</sup>SIA-Lab of Tsinghua AIR and ByteDance Seed</span>
                            <span lang="zh"><sup>6</sup>æ¸…å-å­—èŠ‚è”åˆå®éªŒå®¤SIA-Lab</span>
                        </span>
                        <div class="affiliation-note">
                            <span lang="en">*Project Lead; â€ Equal Contribution</span>
                            <span lang="zh">*é¡¹ç›®è´Ÿè´£äºº; â€ åŒç­‰è´¡çŒ®</span>
                        </div>
                        <div class="affiliation-note">
                            <span lang="en">Contact: <a href="mailto:jiangjiec@bytedance.com">jiangjiec@bytedance.com</a></span>
                            <span lang="zh">è”ç³»æ–¹å¼: <a href="mailto:jiangjiec@bytedance.com">jiangjiec@bytedance.com</a></span>
                        </div>
                    </div>
                    <div class="publication-links">
                        <span class="link-block">
                            <a href="http://arxiv.org/abs/2505.19914" class="external-link button is-dark">
                                <span class="icon">
                                    <i class="fas fa-file-pdf"></i>
                                </span>
                                <span lang="en">Paper</span>
                                <span lang="zh">è®ºæ–‡</span>
                            </a>
                        </span>
                        <span class="link-block">
                            <a href="https://github.com/BytedTsinghua-SIA/Enigmata" class="external-link button is-dark">
                                <span class="icon">
                                    <i class="fas fa-database"></i>
                                </span>
                                <span lang="en">Code</span>
                                <span lang="zh">ä»£ç </span>
                            </a>
                        </span>
                        <span class="link-block">
                            <a href="https://huggingface.co/datasets/BytedTsinghua-SIA/Enigmata-Eval" class="external-link button is-dark">
                                <span class="icon">
                                    <i class="fas fa-database"></i>
                                </span>
                                <span lang="en">Evaluation</span>
                                <span lang="zh">è¯„ä¼°</span>
                            </a>
                        </span>
                        <span class="link-block">
                            <a href="https://huggingface.co/BytedTsinghua-SIA/Enigmata-Qwen2.5-32B" class="external-link button is-dark">
                                <span class="icon">
                                    ğŸ¤—
                                </span>
                                <span lang="en">Model</span>
                                <span lang="zh">æ¨¡å‹</span>
                            </a>
                        </span>
                    </div>
                </div>
            </div>
        </div>
    </section>

<section class="section" id="introduction">
    <div class="container">
        <div class="columns is-centered">
            <div class="column is-10">
                <h2 class="title is-3">
                    <span lang="en">Introduction</span>
                    <span lang="zh">å¼•è¨€</span>
                </h2>
                <div class="content">

                    <p lang="en">
                        We propose a novel long-context processing framework â€” <strong>MemAgent</strong>, which directly optimizes long-context tasks through end-to-end Reinforcement Learning without altering the underlying model architecture.
                    </p>
                    <p lang="zh">
                        æˆ‘ä»¬æ¨å‡ºäº†<strong>MemAgent</strong>ï¼Œè¿™æ˜¯ä¸€ä¸ªå…¨æ–°çš„é•¿æ–‡æœ¬å¤„ç†æ¡†æ¶ï¼Œèƒ½å¤Ÿé€šè¿‡ç«¯åˆ°ç«¯çš„å¼ºåŒ–å­¦ä¹ ç›´æ¥ä¼˜åŒ–é•¿æ–‡æœ¬ä»»åŠ¡æ€§èƒ½ï¼Œè€Œæ— éœ€æ›´æ”¹åº•å±‚æ¨¡å‹æ¶æ„ã€‚
                    </p>
                    <p lang="en">
                        <strong>MemAgent</strong> achieves three core breakthroughs:
                    </p>
                    <p lang="zh">
                        <strong>MemAgent</strong> å®ç°äº†ä¸‰å¤§æ ¸å¿ƒçªç ´ï¼š
                    </p>
                    <div
                        style="background-color: #f8fafc; border-radius: 12px; border-left: 6px solid #3a76ed; padding: 1.2rem; margin-bottom: 1.5rem;">
                            <div style="display: flex; flex-direction: column; gap: 0.8rem;">
                                <div style="display: flex; align-items: flex-start; gap: 0.8rem;"> 
                                    <div
                                        style="background-color: #3a76ed; color: white; padding: 0.4rem; border-radius: 50%; font-size: 0.9rem; display: flex; align-items: center; justify-content: center; min-width: 2rem; height: 2rem;">
                                        1
                                    </div>
                                    <div>
                                        <p style="margin: 0; line-height: 1.4;" lang="en"><strong>Novel memory mechanism: </strong>We introduce a notepad-style agent workflow, where the agent reads input text segment-by-segment, and efficiently updates a fixed-length memory via an overwrite strategy. This design allows the model to process virtually arbitrary-length inputs within a fixed context window, fundamentally overcoming the rigid window-size limitation of traditional Transformer architectures.</p>
                                        <p style="margin: 0; line-height: 1.4;" lang="zh"><strong>æ–°å‹è®°å¿†æœºåˆ¶ï¼š</strong>
                                            æˆ‘ä»¬å¼•å…¥äº†ä¸€ç§è®°äº‹æœ¬å¼çš„å·¥ä½œæµï¼ŒAgent ä»¥åˆ†æ®µæ–¹å¼è¯»å–æ–‡æœ¬ï¼Œå¹¶å€ŸåŠ©è¦†å†™ç­–ç•¥é«˜æ•ˆæ›´æ–°è®°å¿†ã€‚è¯¥è®¾è®¡ä½¿å¾—æ¨¡å‹èƒ½å¤Ÿåœ¨å›ºå®šä¸Šä¸‹æ–‡çª—å£å†…å¤„ç†å‡ ä¹ä»»æ„é•¿åº¦çš„è¾“å…¥ï¼Œä»æ ¹æœ¬ä¸Šçªç ´äº†ä¼ ç»Ÿ Transformer æ¶æ„çš„çª—å£é•¿åº¦é™åˆ¶ã€‚</p>
                                    </div>
                                </div>
                                
                                <div style="display: flex; align-items: flex-start; gap: 0.8rem;">
                                    <div
                                        style="background-color: #3a76ed; color: white; padding: 0.4rem; border-radius: 50%; font-size: 0.9rem; display: flex; align-items: center; justify-content: center; min-width: 2rem; height: 2rem;">
                                        2
                                    </div>
                                    <div>
                                    <p style="margin: 0; line-height: 1.4;" lang="en"><strong>O(n) linear complexity:</strong> Our innovative agent workflow decouples computational and memory costs from input length, achieving O(n) linear time complexity. This effectively addresses the quadratic bottleneck faced by standard attention mechanisms in long-sequence processing.</p>
                                    <p style="margin: 0; line-height: 1.4;" lang="zh"><strong>O(n) çº¿æ€§å¤æ‚åº¦ï¼š</strong>
                                        è¿™ä¸€åˆ›æ–°æ€§çš„ Agent è®¾è®¡å°†è®¡ç®—ä¸æ˜¾å­˜å¼€é”€ä¸æ–‡æœ¬é•¿åº¦è§£è€¦ï¼Œä½¿å¾—å¤„ç†é•¿æ–‡æœ¬çš„å¤æ‚åº¦ç”±åŸæœ¬çš„äºŒæ¬¡æ–¹å¢é•¿è½¬å˜ä¸ºçº¿æ€§å¢é•¿ã€‚</p>
                                    </div>
                                </div>

                                <div style="display: flex; align-items: flex-start; gap: 0.8rem;">
                                    <div
                                        style="background-color: #3a76ed; color: white; padding: 0.4rem; border-radius: 50%; font-size: 0.9rem; display: flex; align-items: center; justify-content: center; min-width: 2rem; height: 2rem;">
                                        3
                                    </div>
                                    <div>
                                        <p style="margin: 0; line-height: 1.4;" lang="en"><strong>RL-driven extrapolation:</strong> We enhance the GRPO algorithm to support multi-turn training over context-independent conversations. Based on this, the trained MemAgent exhibits unprecedented extrapolation performance, scaling from training on 32K-context data to 3.5M-token QA tasks with less than 5% performance degradation.</p>
                                        <p style="margin: 0; line-height: 1.4;" lang="zh"><strong>å¼ºåŒ–å­¦ä¹ é©±åŠ¨çš„å¤–æ¨èƒ½åŠ›:</strong>
                                            æˆ‘ä»¬æ”¹è¿›äº† GRPO ç®—æ³•ï¼Œä½¿å…¶æ”¯æŒç‹¬ç«‹ä¸Šä¸‹æ–‡çš„å¤šè½®ç”Ÿæˆè®­ç»ƒã€‚åŸºäºæ­¤ï¼Œè®­ç»ƒå‡ºçš„ MemAgent åœ¨32Kä¸Šä¸‹æ–‡é•¿åº¦çš„æ•°æ®ä¸Šè®­ç»ƒåï¼Œèƒ½å¤Ÿæ— æŸå¤–æ¨è‡³3.5M tokençš„é—®ç­”ä»»åŠ¡ä¸­ï¼Œæ€§èƒ½ä¸‹é™ä½äº5%ã€‚</p>
                                    </div>
                                </div>                                
                            </div>
                    </div>

                    <p lang="en">
                        Through a simple yet effective design, we demonstrate the first truly trainable memory mechanism powered by reinforcement learning, showcasing the vast potential of using RL to optimize task-specific agent workflows.
                    </p>
                    <p lang="zh">
                        æˆ‘ä»¬ä»¥ä¸€ç§ç®€æ´è€Œé«˜æ•ˆçš„æ–¹å¼ï¼Œé¦–æ¬¡å®ç°äº†çœŸæ­£æ„ä¹‰ä¸Šçš„ã€ç”±å¼ºåŒ–å­¦ä¹ èµ‹äºˆçš„å¯è®­ç»ƒè®°å¿†èƒ½åŠ›ï¼Œå……åˆ†å±•ç°äº†å¼ºåŒ–å­¦ä¹ åœ¨ä¼˜åŒ–ç‰¹å®šå·¥ä½œæµæ–¹é¢çš„å·¨å¤§æ½œåŠ›ã€‚
                    </p>

                    <strong><em style="color: #3a76ed"><center lang="en">We believe MemAgent paves the way for the next generation of scalable long-context LLMs.</center></em></strong>
                    <strong><em style="color: #3a76ed"><center lang="zh">æˆ‘ä»¬ç›¸ä¿¡ï¼ŒMemAgent ä¸ºä¸‹ä¸€ä»£å¯æ‰©å±•çš„é•¿ä¸Šä¸‹æ–‡å¤§è¯­è¨€æ¨¡å‹å¼€è¾Ÿäº†æ–°è·¯å¾„ã€‚</center></em></strong>

                </div>
            </div>
        </div>
    </div>
</section>


<section class="section" id="method">
    <div class="container">
        <div class="columns is-centered">
            <div class="column is-10">
                <h2 class="title is-3">
                    <span lang="en">Method</span>
                    <span lang="zh">æ–¹æ³•ä»‹ç»</span>
                </h2>
                <div class="content">

                    <p lang="en">
                        Inspired by human behavioral patterns when processing long texts, and drawing from the work of Neural Turing Machine and Memory Network that combine neural networks with memory mechanisms, we propose a new long-text processing solution that requires no model architecture modifications:
                        <br><strong style="color:#3273dc;">| Equipping LLMs with dynamically updating "Memory Modules"</strong>.
                    </p>
                    <p lang="zh">
                        å—äººç±»å¤„ç†é•¿æ–‡æœ¬æ—¶çš„è¡Œä¸ºæ¨¡å¼å¯å‘ï¼Œå¹¶å€Ÿé‰´äº†Neural Turing Machineå’ŒMemory Networkç­‰ç¥ç»ç½‘ç»œä¸è®°å¿†æœºåˆ¶ç»“åˆçš„å·¥ä½œï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ— éœ€ä¿®æ”¹æ¨¡å‹æ¶æ„çš„é•¿æ–‡å¤„ç†æ–°æ–¹æ¡ˆâ€”â€”<strong>MemAgent</strong>ï¼š
                        <br><strong style="color:#3273dc;">| ç»™LLMè£…ä¸ŠåŠ¨æ€æ›´æ–°çš„"è®°å¿†æ¨¡å—"</strong>ã€‚
                    </p>

                    <p lang="en">
                        <strong>MemAgent</strong> introduces a fixed-length auxiliary memory panel that allows the model to read input in chunks when processing long texts, and actively update memory state after each chunk, thereby achieving a new workflow of "local processing + global fusion". This memory module continuously updates dynamically during inference and assists in generating final output by aggregating key information in memory after all chunks are processed.
                    </p>
                    <p lang="zh">
                        <strong>MemAgent</strong>å¼•å…¥äº†ä¸€ä¸ªå›ºå®šé•¿åº¦çš„è¾…åŠ©è®°å¿†é¢æ¿ï¼Œå…è®¸æ¨¡å‹åœ¨å¤„ç†é•¿æ–‡æœ¬æ—¶ä»¥åˆ†æ®µçš„æ–¹å¼è¯»å–è¾“å…¥ï¼Œå¹¶åœ¨æ¯ä¸€æ®µä¹‹åä¸»åŠ¨æ›´æ–°è®°å¿†çŠ¶æ€ï¼Œä»è€Œå®ç°"å±€éƒ¨å¤„ç† + å…¨å±€èåˆ"çš„æ–°å‹å·¥ä½œæµã€‚è¯¥è®°å¿†æ¨¡å—åœ¨æ¨ç†è¿‡ç¨‹ä¸­ä¸æ–­åŠ¨æ€æ›´æ–°ï¼Œå¹¶åœ¨æ‰€æœ‰æ®µè½å¤„ç†å®Œæ¯•åï¼Œé€šè¿‡èšåˆè®°å¿†ä¸­çš„å…³é”®ä¿¡æ¯ååŠ©ç”Ÿæˆæœ€ç»ˆè¾“å‡ºã€‚
                    </p>

                    <figure class="image" style="max-width: 800px; margin: 2rem auto;">
                        <img src="figs/method_00.png" alt="MemAgent Architecture Overview">
                    </figure>

                    <p lang="en"><strong>Traditional Text Modeling:</strong></p>
                    <p lang="en">
                        Traditional autoregressive language models model token sequences of length N through the following approach:
                    </p>
                    <p lang="zh"><strong>ä¼ ç»Ÿæ–‡æœ¬å»ºæ¨¡ï¼š</strong></p>
                    <p lang="zh">
                        ä¼ ç»Ÿçš„è‡ªå›å½’è¯­è¨€æ¨¡å‹é€šè¿‡ä»¥ä¸‹æ–¹å¼å»ºæ¨¡é•¿åº¦ä¸ºNçš„tokenåºåˆ—ï¼š
                    </p>
                    <div class="math-center">
                        $p(\mathbf{x}_{1:N}) = p(x_1) \prod_{n=2}^{N} p(x_n \mid \mathbf{x}_{1:n-1})$
                    </div>
                    <p lang="en">
                        This method requires caching all previously generated tokens, leading to computational costs that grow quadratically with sequence length.
                    </p>
                    <p lang="zh">
                        è¿™ç§æ–¹æ³•éœ€è¦ç¼“å­˜æ‰€æœ‰å…ˆå‰ç”Ÿæˆçš„tokenï¼Œå¯¼è‡´è®¡ç®—æˆæœ¬éšåºåˆ—é•¿åº¦å‘ˆäºŒæ¬¡æ–¹å¢é•¿ã€‚
                    </p>

                    <hr>

                    <p lang="en"><strong>MemAgent Core Architecture:</strong></p>
                    <ol lang="en">
                      <li><strong>Chunk Processing:</strong> Divide the input sequence into K contiguous chunks <span class="nowrap-math">\((c^1, c^2, \ldots, c^K)\)</span>, with each chunk containing at most <span class="nowrap-math">\(C\)</span> tokens.</li>
                      <li><strong>Iterative Processing:</strong> Process chunks sequentially, maintaining constant computational cost per chunk.</li>
                    </ol>

                    <p lang="zh"><strong>MemAgent æ ¸å¿ƒæ¶æ„ï¼š</strong></p>
                    <ol lang="zh">
                      <li><strong>åˆ†å—å¤„ç†ï¼š</strong> å°†è¾“å…¥åºåˆ—åˆ†å‰²ä¸ºKä¸ªè¿ç»­å— <span class="nowrap-math">\((c^1, c^2, \ldots, c^K)\)</span>ï¼Œæ¯å—æœ€å¤šåŒ…å« <span class="nowrap-math">\(C\)</span> ä¸ªtokenã€‚</li>
                      <li><strong>å¾ªç¯å¤„ç†ï¼š</strong> æŒ‰å—é¡ºåºå¤„ç†ï¼Œæ¯å—çš„è®¡ç®—æˆæœ¬ä¿æŒæ’å®šã€‚</li>
                    </ol>

                    <p lang="en"><strong>Training MemAgent with Multi-conv RL</strong></p>
                    <p lang="en">
                        After introducing latent memory variables <span class="nowrap-math">\(m^{1:K-1}\)</span> and initial state <span class="nowrap-math">\(m^0 = \emptyset\)</span>, the autoregressive decomposition is reformulated as:
                    </p>
                    <p lang="zh"><strong>é‡æ–°å»ºæ¨¡è¯­è¨€æ¨¡å‹çš„ç”Ÿæˆè¿‡ç¨‹ï¼š</strong></p>
                    <p lang="zh">
                        å¼•å…¥æ½œåœ¨è®°å¿†å˜é‡<span class="nowrap-math">\(m^{1:K-1}\)</span>å’Œåˆå§‹çŠ¶æ€<span class="nowrap-math">\(m^0 = \emptyset\)</span>åï¼Œè‡ªå›å½’åˆ†è§£è¢«é‡æ–°è¡¨è¿°ä¸ºï¼š
                    </p>

                    <div class="math-center">
                          $p(\mathbf{x}_{1:N}) = \sum_{\mathbf{m}^{1:K-1}} \prod_{k=1}^{K}
                          \underbrace{p(\mathbf{c}^k \mid \mathbf{m}^{k-1})}_{\text{read}} \cdot
                          \underbrace{p(\mathbf{m}^k \mid \mathbf{c}^k, \mathbf{m}^{k-1})}_{\text{write}}$
                    </div>

                    <h4 lang="zh"><strong>å¤šè½®å¯¹è¯å¼ºåŒ–å­¦ä¹ è®­ç»ƒ MemAgent </strong></h4>
                    <p lang="en">
                        We use Reinforcement Learning with Verifiable Rewards (RLVR), which currently demonstrates outstanding performance in the reasoning domain, to train MemAgent, rather than simple fine-tuning or instruction engineering. For this purpose, we extend the existing DAPO algorithm to further support end-to-end optimization of AgentWorkflow with multi-conversation independent dialogues.
                    </p>
                    <p lang="zh">
                        æˆ‘ä»¬ä½¿ç”¨ç›®å‰åœ¨æ¨ç†é¢†åŸŸè¡¨ç°å‡ºå“è¶Šæ€§èƒ½çš„åŸºäºå¯éªŒè¯ç»“æœçš„å¼ºåŒ–å­¦ä¹ ï¼ˆRLVRï¼‰æ¥è®­ç»ƒMemAgentï¼Œè€Œéç®€å•çš„è¿›è¡Œå¾®è°ƒæˆ–æŒ‡ä»¤å·¥ç¨‹ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æ‰©å±•äº†ç°æœ‰çš„DAPOç®—æ³•ï¼Œä½¿å…¶è¿›ä¸€æ­¥æ”¯æŒäº†å…·æœ‰å¤šè½®ç‹¬ç«‹å¯¹è¯çš„Agent Workflowçš„ç«¯åˆ°ç«¯ä¼˜åŒ–ã€‚
                    </p>

                    <div class="columns is-vcentered">
                        <div class="column">
                            <figure class="image">
                                <img src="figs/algo_00.png" alt="RL Flow">
                            </figure>
                        </div>
                        <div class="column">
                            <figure class="image">
                                <img src="figs/template.png" alt="RL Template">
                            </figure>
                        </div>
                    </div>

                    <p lang="en"><strong>Multi-Conv Training Mechanism:</strong> For each input sample, multiple sets of independent conversation sequences are generated in parallel through the model.</p>
                    <p lang="zh"><strong>å¤šè½®å¯¹è¯è®­ç»ƒæœºåˆ¶ï¼š</strong>å¯¹äºæ¯ä¸ªè¾“å…¥æ ·æœ¬ï¼Œä¼šé€šè¿‡æ¨¡å‹å¹¶è¡Œç”Ÿæˆå¤šç»„ç‹¬ç«‹å¯¹è¯åºåˆ—ã€‚</p>

                    <p lang="en"><strong>Reward Calculation and Distribution:</strong> The system identifies the final answer based on the last set of responses, calculates its reward value, then intelligently distributes this reward to all associated conversation sequences through group normalization.</p>
                    <p lang="zh"><strong>å¥–åŠ±è®¡ç®—ä¸åˆ†é…ï¼š</strong>ç³»ç»Ÿæ ¹æ®æœ€åä¸€ç»„å›ç­”ï¼Œè¯†åˆ«æœ€ç»ˆç­”æ¡ˆï¼Œè®¡ç®—å…¶å¥–åŠ±å€¼ï¼Œç„¶åå°†è¯¥å¥–åŠ±é€šè¿‡ç»„å½’ä¸€åŒ–æ–¹å¼æ™ºèƒ½åˆ†é…åˆ°æ‰€æœ‰å…³è”å¯¹è¯åºåˆ—ã€‚</p>

                    <p lang="en"><strong>Policy Optimization Objective:</strong> Loss is calculated per chunk, adopting a three-dimensional optimization structure of (group, conversation round, token), maintaining independence of each conversation throughout the process.</p>
                    <p lang="zh"><strong>ç­–ç•¥ä¼˜åŒ–ç›®æ ‡ï¼š</strong>ä»¥æ¯ä¸ªchunkä¸ºå•ä½è®¡ç®—æŸå¤±ï¼ˆå¦‚ä¸‹å›¾æ‰€ç¤ºï¼‰ï¼Œé‡‡ç”¨ï¼ˆç»„åˆ«ã€å¯¹è¯è½®æ¬¡ã€tokenï¼‰ä¸‰ç»´ä¼˜åŒ–ç»“æ„ï¼Œæ•´ä¸ªè¿‡ç¨‹ä¿æŒå„å¯¹è¯çš„ç‹¬ç«‹æ€§ï¼š</p>
                    <div class="has-text-centered">
                        <p>
                            $$ 
                            \begin{aligned}
                            \mathcal{J}_{\text{GRPO}}(\theta) =\quad &\mathbb{E}_{(q,a)\sim \mathcal{D}, \{o_{i,j}\}_{i=1}^G\sim \pi_{\theta_\text{old}}(\cdot\mid q,~o_{i,j-1})} \\
                            &\Bigg[\frac{1}{\sum_{i=1}^{G}\sum_{j=1}^{n_i}|o_{i,j}|}\sum_{i=1}^{G}\sum_{j=1}^{n_i}\sum_{t=1}^{|o_{i,j}|}
                            \Big(\mathcal{C}_{i,j,t} - \beta D_{\text{KL}}(\pi_{\theta} || \pi_{\text{ref}} )\Big) \Bigg] \\
                            \text{where } \mathcal{C}_{i,j,t} = &\min\Big(r_{i,j,t}(\theta) \hat{A}_{i,j,t},  
                            \ \text{clip} \Big( r_{i,j,t}(\theta), 1 - {\varepsilon}, 1 + {\varepsilon} \Big) \hat{A}_{i,j,t}\Big)
                            \end{aligned}
                            $$
                        </p>
                    </div>

                </div>
            </div>
        </div>
    </div>
</section>


<section class="section" id="experiments">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-10">
        <h2 class="title is-3">
          <span lang="en">Experiments</span>
          <span lang="zh">å®éªŒåˆ†æ</span>
        </h2>
        <div class="content">

          <h4 lang="en"><strong>Main Results</strong></h4>
          <h4 lang="zh"><strong>ä¸»å®éªŒç»“æœ</strong></h4>

          <p lang="en">
                <strong>Baseline Models:</strong> Experiments show that existing long-text models universally suffer from severe performance degradation on ultra-long sequences:
                <ul>
                  <li>QwenLong-L1 series: Accuracy drops sharply by over 40 percentage points when text length exceeds 56K.</li>
                  <li>Qwen2.5-Instruct-1M series: Nominally supports 1M tokens, but performance drops to 0 at 896K.</li>
                  <li>DS-distill series: Performance decays exponentially with length, becoming almost completely ineffective at 224K.</li>
                </ul>
          </p>

          <p lang="zh">
                <strong>åŸºçº¿æ¨¡å‹ï¼š</strong> å®éªŒæ˜¾ç¤ºï¼Œç°æœ‰é•¿æ–‡æœ¬æ¨¡å‹åœ¨è¶…é•¿åºåˆ—ä¸Šæ™®éå­˜åœ¨ä¸¥é‡çš„æ€§èƒ½é€€åŒ–ï¼š
                <ul>
                  <li>QwenLong-L1ç³»åˆ—ï¼šåœ¨æ–‡æœ¬é•¿åº¦è¶…è¿‡56Kåå‡†ç¡®ç‡æ€¥å‰§ä¸‹é™ï¼Œé™å¹…è¶…è¿‡40ä¸ªç™¾åˆ†ç‚¹ã€‚</li>
                  <li>Qwen2.5-Instruct-1Mç³»åˆ—ï¼šæ ‡ç§°æ”¯æŒ1Mï¼Œä½†åœ¨896Kæ—¶æ€§èƒ½é™ä¸º0ã€‚</li>
                  <li>DS-distillç³»åˆ—ï¼šæ€§èƒ½éšé•¿åº¦å‘ˆæŒ‡æ•°çº§è¡°å‡ï¼Œåœ¨224Kæ—¶å‡ ä¹å®Œå…¨å¤±æ•ˆã€‚</li>
                </ul>
          </p>

          <p lang="en">
                <strong>MemAgent:</strong> Demonstrates extremely high stability in ultra-long text processing tasks:
                <ul>
                  <li>MemAgent-14B: Shows only marginal performance decline (<5%) in 3.5M ultra-long text tests, achieving lossless extrapolation.</li>
                  <li>MemAgent-7B: While showing slight performance decline on the longest texts, overall performance far exceeds other models.</li>
                </ul>
          </p>

          <p lang="zh">
                <strong>MemAgentï¼š</strong> åœ¨è¶…é•¿æ–‡æœ¬å¤„ç†ä»»åŠ¡ä¸­è¡¨ç°å‡ºæé«˜ç¨³å®šæ€§ï¼š
                <ul>
                  <li>MemAgent-14Bï¼šåœ¨3.5Mè¶…é•¿æ–‡æœ¬æµ‹è¯•ä¸­ä»…å‡ºç°è¾¹é™…æ€§èƒ½ä¸‹é™ï¼ˆ<5%ï¼‰ï¼Œå®ç°äº†æ— æŸå¤–æ¨ã€‚</li>
                  <li>MemAgent-7Bï¼šåœ¨æœ€é•¿æ–‡æœ¬ä¸Šè™½ç•¥æœ‰æ€§èƒ½ä¸‹é™ï¼Œä½†æ€»ä½“è¡¨ç°è¿œè¶…å…¶ä»–æ¨¡å‹ã€‚</li>
                </ul>
          </p>

          <figure class="image" style="max-width: 800px; margin: 2rem auto;">
            <img src="figs/main_result_00.png" alt="Main Results">
          </figure>

          <h4 lang="en"><strong>Ablation Study</strong></h4>
          <h4 lang="zh"><strong>æ¶ˆèå®éªŒ</strong></h4>

          <p lang="en">
                To verify the contribution of each component in MemAgent, we conducted systematic ablation experiments:
                <ol>
                  <li><strong>Base Model:</strong> After exceeding the training window, information loss leads to sharp performance decline, unable to achieve extrapolation.</li>
                  <li><strong>MemAgent (without RL training):</strong> Has certain processing capabilities, but still shows obvious performance loss on long text tasks.</li>
                  <li><strong>MemAgent:</strong> Reinforcement learning training significantly improves extrapolation capability, achieving near-lossless performance.</li>
                </ol>
          </p>

          <p lang="zh">
                ä¸ºéªŒè¯MemAgentå„ç»„ä»¶çš„è´¡çŒ®ï¼Œæˆ‘ä»¬å¼€å±•äº†ç³»ç»Ÿçš„æ¶ˆèå®éªŒï¼š
                <ol>
                  <li><strong>åŸºç¡€æ¨¡å‹ï¼š</strong> åœ¨è¶…å‡ºè®­ç»ƒçª—å£åï¼Œä¿¡æ¯ç¼ºå¤±å¯¼è‡´æ€§èƒ½æ€¥å‰§ä¸‹é™ï¼Œæ— æ³•å®ç°å¤–æ¨ã€‚</li>
                  <li><strong>MemAgentï¼ˆæœªç»RLè®­ç»ƒï¼‰ï¼š</strong> å…·å¤‡ä¸€å®šå¤„ç†èƒ½åŠ›ï¼Œä½†åœ¨é•¿æ–‡æœ¬ä»»åŠ¡ä¸‹ä»å‡ºç°æ˜æ˜¾æ€§èƒ½æŸå¤±ã€‚</li>
                  <li><strong>MemAgentï¼š</strong> å¼ºåŒ–å­¦ä¹ è®­ç»ƒæ˜¾è‘—æå‡å¤–æ¨èƒ½åŠ›ï¼Œè¾¾åˆ°è¿‘ä¹æ— æŸæ€§èƒ½ã€‚</li>
                </ol>
          </p>

          <figure class="image" style="max-width: 800px; margin: 2rem auto;">
            <img src="figs/ablation_00.png" alt="Ablation Study">
          </figure>

          <h4 lang="en"><strong>RULER Benchmark Testing and OOD Capability Analysis</strong></h4>
          <h4 lang="zh"><strong>RULERåŸºå‡†æµ‹è¯•ä¸OODèƒ½åŠ›åˆ†æ</strong></h4>

          <p lang="en">
            <strong>RULER Benchmark Testing:</strong> This is the current standard test set for long-text extrapolation capability research, with the core advantage of controllable length generation tasks.
          </p>

          <p lang="zh">
            <strong>RULERåŸºå‡†æµ‹è¯•ï¼š</strong> è¿™æ˜¯å½“å‰é•¿æ–‡æœ¬å¤–æ¨èƒ½åŠ›ç ”ç©¶çš„æ ‡å‡†æµ‹è¯•é›†ï¼Œå…¶æ ¸å¿ƒä¼˜åŠ¿æ˜¯å¯æ§é•¿åº¦ç”Ÿæˆä»»åŠ¡ã€‚
          </p>

          <div class="box" style="background: #f8f9fa; border: 1px solid #ddd; border-radius: 10px; padding: 1.5rem;">
            <div class="columns is-multiline is-variable is-4">
              <div class="column is-6">
                <div class="box has-background-white-ter">
                  <strong lang="en">Needle-in-a-Haystack</strong>
                  <strong lang="zh">å¤§æµ·æé’ˆï¼ˆNeedle-in-a-Haystackï¼‰</strong>
                  <p lang="en">Locating key needles in ultra-long texts, including 8 types of interference variants.</p>
                  <p lang="zh">åœ¨è¶…é•¿æ–‡æœ¬ä¸­å®šä½å…³é”®needleï¼ŒåŒ…å«8ç±»å¹²æ‰°å˜ä½“ã€‚</p>
                </div>
              </div>
              <div class="column is-6">
                <div class="box has-background-white-ter">
                  <strong lang="en">Variable Tracking</strong>
                  <strong lang="zh">å˜é‡è¿½è¸ªï¼ˆVariable Trackingï¼‰</strong>
                  <p lang="en">Simulating program analysis scenarios, tracking variable references and assignment relationships.</p>
                  <p lang="zh">æ¨¡æ‹Ÿç¨‹åºåˆ†æåœºæ™¯ï¼Œè¿½è¸ªå˜é‡å¼•ç”¨å’Œèµ‹å€¼å…³ç³»ã€‚</p>
                </div>
              </div>
              <div class="column is-6">
                <div class="box has-background-white-ter">
                  <strong lang="en">Aggregation</strong>
                  <strong lang="zh">èšåˆä»»åŠ¡ï¼ˆAggregationï¼‰</strong>
                  <p lang="en">Aggregating scattered information to evaluate the model's ability to grasp global features.</p>
                  <p lang="zh">æ±‡æ€»åˆ†æ•£ä¿¡æ¯ï¼Œè¯„ä¼°æ¨¡å‹å¯¹å…¨å±€ç‰¹å¾çš„æŒæ¡èƒ½åŠ›ã€‚</p>
                </div>
              </div>
              <div class="column is-6">
                <div class="box has-background-white-ter">
                  <strong lang="en">Question Answering (QA)</strong>
                  <strong lang="zh">é—®ç­”ä»»åŠ¡ï¼ˆQAï¼‰</strong>
                  <p lang="en">Conducting multi-hop complex reasoning to test the model's contextual understanding and QA capabilities.</p>
                  <p lang="zh">è¿›è¡Œå¤šè·³å¤æ‚æ¨ç†ï¼Œæµ‹è¯•æ¨¡å‹ä¸Šä¸‹æ–‡ç†è§£ä¸é—®ç­”èƒ½åŠ›ã€‚</p>
                </div>
              </div>
            </div>
          </div>

          <p lang="en">
                <strong>Experimental Results Analysis:</strong> We use heatmaps to visualize the performance of different models across different length ranges and task types:
                <ul>
                  <li><strong>MemAgent:</strong> Outperforms existing models on all task types, showing significant performance advantages.</li>
                  <li><strong>MemAgent (untrained):</strong> Superior to base models in most cases, but still shows performance decline at extrapolation lengths.</li>
                  <li><strong>Base Models:</strong> Distill/Instruct series universally fail on ultra-long text tasks.</li>
                  <li><strong>QwenLong Series:</strong> Performance drops dramatically on ultra-long texts, even worse than base models.</li>
                  <li><strong>Qwen-1M Series:</strong> Performs reasonably on simple tasks but drops sharply on complex reasoning tasks.</li>
                </ul>
          </p>

          <p lang="zh">
                <strong>å®éªŒç»“æœåˆ†æï¼š</strong> æˆ‘ä»¬ä½¿ç”¨çƒ­åŠ›å›¾å¯è§†åŒ–ä¸åŒæ¨¡å‹åœ¨ä¸åŒé•¿åº¦åŒºé—´å’Œä»»åŠ¡ç±»å‹ä¸‹çš„æ€§èƒ½ï¼š
                <ul>
                  <li><strong>MemAgentï¼š</strong> æ‰€æœ‰ä»»åŠ¡ç±»å‹ä¸Šå‡ä¼˜äºç°æœ‰æ¨¡å‹ï¼Œå±•ç°æ˜¾è‘—æ€§èƒ½ä¼˜åŠ¿ã€‚</li>
                  <li><strong>MemAgentï¼ˆæœªè®­ç»ƒï¼‰ï¼š</strong> åœ¨å¤§å¤šæ•°æƒ…å†µä¸‹ä¼˜äºåŸºç¡€æ¨¡å‹ï¼Œä½†å¤–æ¨é•¿åº¦ä¸Šä»å‡ºç°æ€§èƒ½ä¸‹é™ã€‚</li>
                  <li><strong>åŸºç¡€æ¨¡å‹ï¼š</strong> Distill/Instructç³»åˆ—åœ¨è¶…é•¿æ–‡æœ¬ä»»åŠ¡ä¸­æ™®éå¤±è´¥ã€‚</li>
                  <li><strong>QwenLongç³»åˆ—ï¼š</strong> åœ¨è¶…é•¿æ–‡æœ¬ä¸‹æ€§èƒ½å‰§é™ï¼Œç”šè‡³ä¸å¦‚åŸºç¡€æ¨¡å‹ã€‚</li>
                  <li><strong>Qwen-1Mç³»åˆ—ï¼š</strong> åœ¨ç®€å•ä»»åŠ¡ä¸Šè¡¨ç°å°šå¯ï¼Œä½†åœ¨å¤æ‚æ¨ç†ä»»åŠ¡ä¸­æ€¥å‰§ä¸‹é™ã€‚</li>
                </ul>
          </p>

          <div class="columns is-multiline">
            <div class="column is-4">
              <figure class="image"><img src="figs/niah_single_1_00.png" alt="NIAH Single 1"></figure>
            </div>
            <div class="column is-4">
              <figure class="image"><img src="figs/niah_single_2_00.png" alt="NIAH Single 2"></figure>
            </div>
            <div class="column is-4">
              <figure class="image"><img src="figs/niah_single_3_00.png" alt="NIAH Single 3"></figure>
            </div>

            <div class="column is-4">
              <figure class="image"><img src="figs/niah_multikey_1_00.png" alt="NIAH Multi 1"></figure>
            </div>
            <div class="column is-4">
              <figure class="image"><img src="figs/niah_multikey_2_00.png" alt="NIAH Multi 2"></figure>
            </div>
            <div class="column is-4">
              <figure class="image"><img src="figs/niah_multikey_3_00.png" alt="NIAH Multi 3"></figure>
            </div>

            <div class="column is-6">
              <figure class="image"><img src="figs/niah_multiquery_00.png" alt="Multi-query"></figure>
            </div>
            <div class="column is-6">
              <figure class="image"><img src="figs/niah_multivalue_00.png" alt="Multi-value"></figure>
            </div>

            <div class="column is-6">
              <figure class="image"><img src="figs/fwe_00.png" alt="FWE"></figure>
            </div>
            <div class="column is-6">
              <figure class="image"><img src="figs/vt_00.png" alt="VT"></figure>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="section" id="conclusion">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-10">
        <h2 class="title is-3">
          <span lang="en">Conclusion</span>
          <span lang="zh">æ€»ç»“</span>
        </h2>
        <div class="content">
          <p lang="zh">
            æœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§å…¨æ–°çš„é•¿æ–‡æœ¬å¤„ç†æ¡†æ¶ <strong>MemAgent</strong>ï¼Œåœ¨ä»¥ä¸‹ä¸‰ä¸ªå…³é”®ç»´åº¦å®ç°äº†é‡è¦çªç ´ï¼š
          </p>
          <ul lang="zh">
            <li><strong>æŠ€æœ¯æ¶æ„çªç ´ï¼š</strong> æå‡ºä¸€ç§åˆ›æ–°æœºåˆ¶ï¼Œä½¿å¤§è¯­è¨€æ¨¡å‹åœ¨å›ºå®šçª—å£é™åˆ¶ä¸‹ä»èƒ½ä»¥ <strong>çº¿æ€§å¤æ‚åº¦</strong>å¤„ç†ä»»æ„é•¿åº¦æ–‡æœ¬ï¼Œä»æ ¹æœ¬ä¸Šçªç ´ä¼ ç»ŸTransformerçš„è®¡ç®—ç“¶é¢ˆã€‚</li>
            <li><strong>æ™ºèƒ½ä½“è®­ç»ƒæ–¹æ³•ï¼š</strong> æ„å»ºäº†ä¸€æ•´å¥—å¼ºåŒ–å­¦ä¹ é©±åŠ¨çš„æ™ºèƒ½ä½“å·¥ä½œæµï¼ŒåŸºäº <strong>å¤šå¯¹è¯GRPO</strong> å®ç°ç«¯åˆ°ç«¯è®­ç»ƒæœºåˆ¶ã€‚</li>
            <li><strong>æ€§èƒ½å¤–æ¨éªŒè¯ï¼š</strong> å¤§é‡å®éªŒè¡¨æ˜ï¼ŒRLè®­ç»ƒèƒ½å¤Ÿå¸®åŠ©æ¨¡å‹å¤–æ¨è‡³è¿œè¶…è®­ç»ƒçª—å£çš„ä»»åŠ¡ä¸­ï¼Œ<strong>æ€§èƒ½ä¸‹é™<5%</strong>ï¼Œæ˜¾è‘—æ‰©å±•LLMèƒ½åŠ›è¾¹ç•Œã€‚</li>
          </ul>

          <p lang="en">
            This study proposes a novel long-context processing framework <strong>MemAgent</strong>, achieving breakthroughs in the following three key dimensions:
          </p>
          <ul lang="en">
            <li><strong>Architectural Innovation:</strong> A novel mechanism enables large language models to process arbitrarily long texts with <strong>linear complexity</strong> under fixed window constraints, fundamentally overcoming the computational bottleneck of traditional Transformers.</li>
            <li><strong>Agent Training Strategy:</strong> A complete reinforcement learning-driven agent workflow is constructed, achieving end-to-end training based on <strong>Multi-Dialogue GRPO</strong>.</li>
            <li><strong>Performance Extrapolation:</strong> Extensive experiments show that RL training enables the model to extrapolate far beyond the training window with <strong>less than 5% degradation</strong>, significantly expanding the capability frontier of LLMs.</li>
          </ul>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section" id="engineering">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-10">
        <h2 class="title is-3">
          <span lang="en">Engineering Bonus</span>
          <span lang="zh">å·¥ç¨‹å½©è›‹</span>
        </h2>
        <div class="content">
          <p lang="zh">
            <strong>MemAgent</strong> çš„æˆåŠŸä¸ä»…ä¾èµ–äºç†è®ºæ–¹æ³•ï¼Œè¿˜å¾—ç›Šäºå·¥ç¨‹ç³»ç»Ÿçš„åˆ›æ–°æ€§æ”¯æŒã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§é€‚é…å¤§æ¨¡å‹è®­ç»ƒçš„æ–°å‹å¼‚æ­¥æ¶æ„ï¼Œå¹¶å®ç°äº†æ¥å£ç»Ÿä¸€ï¼Œæ˜¾è‘—æå‡äº†è®­ç»ƒæ•ˆç‡ä¸æ˜“ç”¨æ€§ã€‚
          </p>
          <ul lang="zh">
            <li><strong>çº¯å¼‚æ­¥æµæ°´çº¿ï¼š</strong> GPU/CPUèµ„æºè§£è€¦ï¼Œ<code>AsyncLLMEngine</code> è´Ÿè´£å¤šèŠ‚ç‚¹æ¨ç†ï¼Œ<code>Ray Worker</code>ç®¡ç†å¸¸é©»CPUä»»åŠ¡æ± ï¼Œé€šè¿‡åç¨‹å®Œæˆèµ„æºè°ƒåº¦ã€‚</li>
            <li><strong>ç»Ÿä¸€APIæ¥å£ï¼š</strong> å…¼å®¹ OpenAI API ä¸ vLLM æ¨ç†ï¼Œæ”¯æŒ <strong>å¤šè½®å·¥å…·è°ƒç”¨ã€å¤šAgentå¹¶è¡Œã€å¤šä»»åŠ¡è®­ç»ƒ</strong>ï¼ŒçœŸæ­£æ¶ˆé™¤ä¼ ç»ŸçŠ¶æ€æœºåœ°ç‹±ã€‚</li>
            <li><strong>æ˜“ç”¨æ€§æ˜¾è‘—æå‡ï¼š</strong> è®­ç»ƒæµç¨‹åªéœ€ç¼–å†™ä¸€ä¸ªæ ‡å‡† OpenAI æ¥å£å‡½æ•°ï¼Œå³å¯å®Œæˆå¤æ‚ä¸Šä¸‹æ–‡æ‹¼æ¥ã€tokenå¤„ç†ä¸çŠ¶æ€ç®¡ç†ã€‚</li>
          </ul>

          <p lang="en">
            The success of <strong>MemAgent</strong> is not only attributed to its theoretical design, but also to the innovative support from the engineering system. We introduce a new asynchronous architecture optimized for large-scale model training, with unified interfaces that significantly improve training efficiency and usability.
          </p>
          <ul lang="en">
            <li><strong>Fully Asynchronous Pipeline:</strong> GPU and CPU resources are decoupled. <code>AsyncLLMEngine</code> handles multi-node inference while <code>Ray Worker</code> manages a persistent CPU task pool, and resource scheduling is completed via coroutines.</li>
            <li><strong>Unified API Interface:</strong> Compatible with both OpenAI API and vLLM inference, supporting <strong>multi-turn tool use, multi-agent parallelism, and multi-task training</strong>, effectively eliminating traditional state machine complexity.</li>
            <li><strong>Significant Usability Improvement:</strong> Training only requires implementing a standard OpenAI-style interface function, which automatically handles complex context stitching, token processing, and state management.</li>
          </ul>

          <div class="columns is-vcentered">
            <div class="column">
              <figure class="image">
                <img src="figs/workflow1.png" alt="Async Engine Workflow 1">
              </figure>
            </div>
            <div class="column">
              <figure class="image">
                <img src="figs/workflow2.png" alt="Async Engine Workflow 2">
              </figure>
            </div>
          </div>

        </div>
      </div>
    </div>
  </div>
</section>




    <section class="section" id="citation">
        <div class="container">
            <div class="columns is-centered">
                <div class="column is-10">
                    <h2 class="title is-3">
                        <span lang="en">ğŸ“ Citation</span>
                        <span lang="zh">ğŸ“ å¼•ç”¨</span>
                    </h2>
                    <div class="content">
                        <p lang="en">If you find this work useful, please cite our paper:</p>
                        <p lang="zh">å¦‚æœæ‚¨å‘ç°è¿™é¡¹å·¥ä½œæœ‰ç”¨ï¼Œè¯·å¼•ç”¨æˆ‘ä»¬çš„è®ºæ–‡ï¼š</p>
                        <pre><code class="latex">
@article{chen2025enigmata,
    title={Enigmata: Scaling Logical Reasoning in Large Language Models with Synthetic Verifiable Puzzles},
    author={Chen, Jiangjie and He, Qianyu and Yuan, Siyu and Chen, Aili and Cai, Zhicheng and Dai, Weinan and Yu, Hongli and Yu, Qiying and Li, Xuefeng and Chen, Jiaze and others},
    journal={arXiv preprint arXiv:2505.19914},
    year={2025}
}
                        </code></pre>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <footer class="footer">
        <div class="container">
            <div class="has-text-centered">
                <p>
                    <span lang="en">Â© 2025 <a href="https://seed.bytedance.com">ByteDance Seed</a>. Modified from <a href="https://github.com/seed-enigmata/seed-enigmata.github.io">R2E-Gym</a>.</span>
                    <span lang="zh">Â© 2025 <a href="https://seed.bytedance.com">å­—èŠ‚è·³åŠ¨Seed</a>. ä¿®æ”¹è‡ª <a href="https://github.com/seed-enigmata/seed-enigmata.github.io">R2E-Gym</a>.</span>
                </p>
            </div>
        </div>
    </footer>


</body>


</html>
